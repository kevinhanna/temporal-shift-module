{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/temporal-shift-module/online_demo')\n",
    "\n",
    "#from mobilenet_v2_tsm_test import MobileNetV2\n",
    "from arch_mobilenetv2 import MobileNetV2\n",
    "\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GroupScale(object):\n",
    "    \"\"\" Rescales the input PIL.Image to the given 'size'.\n",
    "    'size' will be the size of the smaller edge.\n",
    "    For example, if height > width, then image will be\n",
    "    rescaled to (size * height / width, size)\n",
    "    size: size of the smaller edge\n",
    "    interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.worker = torchvision.transforms.Scale(size, interpolation)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return [self.worker(img) for img in img_group]\n",
    "\n",
    "\n",
    "\n",
    "class GroupCenterCrop(object):\n",
    "    def __init__(self, size):\n",
    "        self.worker = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return [self.worker(img) for img in img_group]\n",
    "\n",
    "\n",
    "\n",
    "class Stack(object):\n",
    "\n",
    "    def __init__(self, roll=False):\n",
    "        self.roll = roll\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        if img_group[0].mode == 'L':\n",
    "            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n",
    "        \n",
    "        elif img_group[0].mode == 'RGB':\n",
    "            if self.roll:\n",
    "                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n",
    "            else:\n",
    "                return np.concatenate(img_group, axis=2)\n",
    "\n",
    "\n",
    "\n",
    "class ToTorchFormatTensor(object):\n",
    "    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n",
    "\n",
    "    def __init__(self, div=True):\n",
    "        self.div = div\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n",
    "        else:\n",
    "            # handle PIL Image\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n",
    "            # put it from HWC to CHW format\n",
    "            # yikes, this transpose takes 80% of the loading time/CPU\n",
    "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        return img.float().div(255) if self.div else img.float()\n",
    "\n",
    "\n",
    "\n",
    "class GroupNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        rep_mean = self.mean * (tensor.size()[0] // len(self.mean))\n",
    "        rep_std = self.std * (tensor.size()[0] // len(self.std))\n",
    "\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, rep_mean, rep_std):\n",
    "            t.sub_(m).div_(s)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def process_output(idx_, history, num_classes):\n",
    "    # idx_: the output of current frame\n",
    "    # history: a list containing the history of predictions\n",
    "    if not REFINE_OUTPUT:\n",
    "        return idx_, history\n",
    "\n",
    "    max_hist_len = int((20/27)*num_classes) # max history buffer\n",
    "\n",
    "    # mask out illegal action\n",
    "    \n",
    "    if num_classes == 27:\n",
    "        if idx_ in [7, 8, 21, 22, 1, 3]:\n",
    "            idx_ = history[-1]\n",
    "\n",
    "        if idx_ == 0:\n",
    "            idx_ = 2\n",
    "\n",
    "    # use only single no action class\n",
    "    elif num_classes == 3: \n",
    "        if idx_ in [2]:\n",
    "            idx_ = history[-1]\n",
    "        \n",
    "        if idx_ == 0:\n",
    "            idx_ = 0\n",
    "    \n",
    "    # history smoothing\n",
    "\n",
    "    if idx_ != history[-1] and len(history) != 1:\n",
    "        if not (history[-1] == history[-2]): #  and history[-2] == history[-3]):\n",
    "            idx_ = history[-1]\n",
    "    \n",
    "\n",
    "    history.append(idx_)\n",
    "    history = history[-max_hist_len:]\n",
    "\n",
    "    return history[-1], history\n",
    "\n",
    "\n",
    "def get_categories(num_classes):\n",
    "\n",
    "    if num_classes == 27:\n",
    "        catigories = [\n",
    "        \"Doing other things\",  # 0\n",
    "        \"Drumming Fingers\",  # 1\n",
    "        \"No gesture\",  # 2\n",
    "        \"Pulling Hand In\",  # 3\n",
    "        \"Pulling Two Fingers In\",  # 4\n",
    "        \"Pushing Hand Away\",  # 5\n",
    "        \"Pushing Two Fingers Away\",  # 6\n",
    "        \"Rolling Hand Backward\",  # 7\n",
    "        \"Rolling Hand Forward\",  # 8\n",
    "        \"Shaking Hand\",  # 9\n",
    "        \"Sliding Two Fingers Down\",  # 10\n",
    "        \"Sliding Two Fingers Left\",  # 11\n",
    "        \"Sliding Two Fingers Right\",  # 12\n",
    "        \"Sliding Two Fingers Up\",  # 13\n",
    "        \"Stop Sign\",  # 14\n",
    "        \"Swiping Down\",  # 15\n",
    "        \"Swiping Left\",  # 16\n",
    "        \"Swiping Right\",  # 17\n",
    "        \"Swiping Up\",  # 18\n",
    "        \"Thumb Down\",  # 19\n",
    "        \"Thumb Up\",  # 20\n",
    "        \"Turning Hand Clockwise\",  # 21\n",
    "        \"Turning Hand Counterclockwise\",  # 22\n",
    "        \"Zooming In With Full Hand\",  # 23\n",
    "        \"Zooming In With Two Fingers\",  # 24\n",
    "        \"Zooming Out With Full Hand\",  # 25\n",
    "        \"Zooming Out With Two Fingers\"  # 26\n",
    "    ]\n",
    "\n",
    "    elif num_classes == 9: \n",
    "\n",
    "        catigories = [\"Fall\", \"SalsaSpin\", \"Taichi\", \"WallPushups\", \"WritingOnBoard\", \"Archery\", \"Hulahoop\", \"Nunchucks\", \"WalkingWithDog\"]\n",
    "    \n",
    "    elif num_classes == 10:\n",
    "\n",
    "        catigories = [\"Fall\", \"SalsaSpin\", \"Taichi\", \"WallPushups\", \"WritingOnBoard\", \"Archery\", \"Hulahoop\", \"Nunchucks\", \"WalkingWithDog\", \"test\"]\n",
    "\n",
    "    elif num_classes == 3 :\n",
    "\n",
    "        catigories = ['Fall', \"Not Fall\", \"Test\"]\n",
    "\n",
    "    elif num_classes == 2:\n",
    "\n",
    "        catigories = [\"Fall\", \"Not Fall\"]\n",
    "\n",
    "    return catigories\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting... \n",
      "\n",
      "Final 0 Attempt Not Fall\n",
      "Final 0 Attempt Not Fall\n",
      "Final 1 Attempt Not Fall\n",
      "Final 2 Attempt Not Fall\n",
      "Final 3 Attempt Not Fall\n",
      "Final 4 Attempt Not Fall\n",
      "Final 5 Attempt Not Fall\n",
      "Final 6 Attempt Not Fall\n",
      "Final 7 Attempt Not Fall\n",
      "Final 8 Attempt Not Fall\n",
      "Final 9 Attempt Not Fall\n",
      "Final 10 Attempt Not Fall\n",
      "Final 11 Attempt Not Fall\n",
      "Final 12 Attempt Not Fall\n",
      "Final 13 Attempt Not Fall\n",
      "Final 14 Attempt Not Fall\n",
      "Final 15 Attempt Not Fall\n",
      "Final 16 Attempt Not Fall\n",
      "Final 17 Attempt Not Fall\n",
      "Final 18 Attempt Not Fall\n",
      "Final 19 Attempt Not Fall\n",
      "Final 20 Attempt Not Fall\n",
      "Final 21 Attempt Not Fall\n",
      "Final 22 Attempt Not Fall\n",
      "Final 23 Attempt Not Fall\n",
      "Final 24 Attempt Not Fall\n",
      "Final 25 Attempt Not Fall\n",
      "Final 26 Attempt Not Fall\n",
      "Final 27 Attempt Not Fall\n",
      "Final 28 Attempt Not Fall\n",
      "Final 29 Attempt Not Fall\n",
      "Final 30 Attempt Not Fall\n",
      "Final 31 Attempt Not Fall\n",
      "Final 32 Attempt Not Fall\n",
      "Final 33 Attempt Not Fall\n",
      "Final 34 Attempt Not Fall\n",
      "Final 35 Attempt Not Fall\n",
      "Final 36 Attempt Not Fall\n",
      "Final 37 Attempt Not Fall\n",
      "Final 38 Attempt Not Fall\n",
      "Final 39 Attempt Not Fall\n",
      "Final 40 Attempt Not Fall\n",
      "Final 41 Attempt Not Fall\n",
      "Final 42 Attempt Not Fall\n",
      "Final 43 Attempt Not Fall\n",
      "Final 44 Attempt Not Fall\n",
      "Final 45 Attempt Not Fall\n",
      "Final 46 Attempt Not Fall\n",
      "Final 47 Attempt Not Fall\n",
      "Final 48 Attempt Not Fall\n",
      "Final 49 Attempt Not Fall\n",
      "Final 50 Attempt Not Fall\n",
      "Final 51 Attempt Not Fall\n",
      "Final 52 Attempt Not Fall\n",
      "Final 53 Attempt Not Fall\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def main(num_classes):\n",
    "\n",
    "\n",
    "    if num_classes not in [2, 3, 9, 10, 27]:\n",
    "        return \"Can only handle 2, 10, and 27 classes\"\n",
    "\n",
    "    else:\n",
    "        catigories = get_categories(num_classes)\n",
    "\n",
    "    cropping = torchvision.transforms.Compose([\n",
    "        GroupScale(256),\n",
    "        GroupCenterCrop(224),\n",
    "    ])\n",
    "\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        cropping,\n",
    "        Stack(roll=False),\n",
    "        ToTorchFormatTensor(div=True),\n",
    "        GroupNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    from torch import nn\n",
    "    torch_module = MobileNetV2(n_class=num_classes)\n",
    "    #print(torch_module.state_dict().keys())\n",
    "    \n",
    "    \n",
    "    if num_classes == 27:\n",
    "        if not os.path.exists(\"mobilenetv2_jester_online.pth.tar\"):  # checkpoint not downloaded\n",
    "            print('Downloading PyTorch checkpoint...')\n",
    "            url = 'https://hanlab.mit.edu/projects/tsm/models/mobilenetv2_jester_online.pth.tar'\n",
    "            urllib.request.urlretrieve(url, './mobilenetv2_jester_online.pth.tar')\n",
    "    \n",
    "\n",
    "        torch_module.load_state_dict(torch.load(\"mobilenetv2_jester_online.pth.tar\"))\n",
    "\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if num_classes == 9 or num_classes == 10:\n",
    "            #KH model_new = torch.load(\"../../pretrained/9cat/ckpt.best.pth.tar\")\n",
    "            model_new = torch.load(\"/data/w251fall/checkpoints/9_Categories/TSM_w251fall_RGB_mobilenetv2_shift8_blockres_avg_segment8_e50/ckpt.best.pth.tar\")\n",
    "    \n",
    "        elif num_classes == 2 or num_classes == 3:\n",
    "            #KH model_new = torch.load(\"../../pretrained/2cat/ckpt.best.pth.tar\")\n",
    "            #model_new = torch.load(\"/data/w251fall/checkpoints/2_Categories/1_TSM_w251fall_RGB_mobilenetv2_shift8_blockres_avg_segment8_e25/ckpt.best.pth.tar\")\n",
    "            model_new = torch.load(\"/data/w251fall/checkpoints/2_Categories/TSM_w251fall_RGB_mobilenetv2_shift8_blockres_avg_segment8_e5/ckpt.best.pth.tar\")\n",
    "            \n",
    "            \n",
    "        # Fixing new model parameter mis-match\n",
    "        state_dict = model_new['state_dict']\n",
    "        #print(state_dict.keys())\n",
    "    \n",
    "        from collections import OrderedDict\n",
    "        new_state_dict = OrderedDict()\n",
    "\n",
    "        for k, v in state_dict.items():\n",
    "            #name = k[7:] # remove `module.`\n",
    "\n",
    "            if \"module.base_model.\" in k:\n",
    "                name = k.replace(\"module.base_model.\", \"\")\n",
    "\n",
    "                if \".net\" in name:\n",
    "                    name = name.replace(\".net\", \"\")\n",
    "\n",
    "\n",
    "            elif \"module.\" in k:\n",
    "                name = k.replace(\"module.new_fc.\", \"classifier.\")\n",
    "        \n",
    "\n",
    "            new_state_dict[name] = v\n",
    "\n",
    "        # load params\n",
    "        torch_module.load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "    torch_module.eval()\n",
    "\n",
    "    #KH cap = cv2.VideoCapture(1)\n",
    "\n",
    "    # set a lower resolution for speed up\n",
    "    #KH cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "    #KH cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "    \n",
    "    # Load jpgs file names fully qualified\n",
    "    \n",
    "    \n",
    "    # Falls\n",
    "    #video_images_dir = '/data/w251fall/jpg/Fall/fall-25-front-urfall.val'\n",
    "    #video_images_dir = '/data/w251fall/jpg/Fall/steph_2682_(1).train'\n",
    "    video_images_dir = '/data/w251fall/jpg/Fall/ten_0002_(10).train'\n",
    "    \n",
    "    # Not Falls\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_HulaHoop_g01_c01.val' # Nunchucks ✓\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_HulaHoop_g02_c01.val' # Nunchucks ✓\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_TaiChi_g23_c01.train' # WallPushUps ✓\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_Archery_g25_c07.train' # Hulahoop ✓\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_Nunchucks_g01_c01.val' # WritingOnBoard X HulaHoop X\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_Nunchucks_g02_c06.val' # WritingOnBoard X\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_WritingOnBoard_g05_c02.val' # Archery ✓\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_WritingOnBoard_g07_c06.val' # Archery ✓\n",
    "    #video_images_dir = '/data/w251fall/jpg/NotFall/v_Archery_g02_c07.val' # HulaHoop ✓ WritingOnBoard X\n",
    "    \n",
    "    \n",
    "    jpg_filenames = [video_images_dir + '/' + s for s in os.listdir(video_images_dir)]\n",
    "\n",
    "    \n",
    "    #full_screen = False\n",
    "    #KH cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "    #KH cv2.resizeWindow(WINDOW_NAME, 640, 480)\n",
    "    #KH cv2.moveWindow(WINDOW_NAME, 0, 0)\n",
    "    #KH cv2.setWindowTitle(WINDOW_NAME, WINDOW_NAME)\n",
    "\n",
    "\n",
    "    shift_buffer = [torch.zeros([1, 3, 56, 56]),\n",
    "                    torch.zeros([1, 4, 28, 28]),\n",
    "                    torch.zeros([1, 4, 28, 28]),\n",
    "                    torch.zeros([1, 8, 14, 14]),\n",
    "                    torch.zeros([1, 8, 14, 14]),\n",
    "                    torch.zeros([1, 8, 14, 14]),\n",
    "                    torch.zeros([1, 12, 14, 14]),\n",
    "                    torch.zeros([1, 12, 14, 14]),\n",
    "                    torch.zeros([1, 20, 7, 7]),\n",
    "                    torch.zeros([1, 20, 7, 7])]\n",
    "\n",
    "\n",
    "    t = None    \n",
    "    index = 0\n",
    "    idx = 0\n",
    "    history = [2]\n",
    "    history_logit = []\n",
    "    history_timing = []\n",
    "    i_frame = -1\n",
    "\n",
    "    #KH while True:\n",
    "    for jpg_filename in jpg_filenames:\n",
    "        \n",
    "        img = cv2.imread(jpg_filename)\n",
    "        \n",
    "        i_frame += 1\n",
    "        #KH _, img = cap.read()  # (480, 640, 3) 0 ~ 255\n",
    "\n",
    "        if i_frame % 1 == 0:\n",
    "            t1 = time.time()\n",
    "            img_tran = transform([Image.fromarray(img).convert('RGB')])\n",
    "            input_var = torch.autograd.Variable(img_tran.view(1, 3, img_tran.size(1), img_tran.size(2)))\n",
    "\n",
    "            #prediction = torch_module(input_var, *shift_buffer) #demo mobilenet\n",
    "            prediction = torch_module(input_var) #arch mobilenet\n",
    "\n",
    "\n",
    "            feat, shift_buffer = prediction[0], prediction[1:]\n",
    "\n",
    "\n",
    "            if SOFTMAX_THRES > 0:\n",
    "\n",
    "                feat_np = feat.detach().numpy().reshape(-1)\n",
    "                feat_np -= feat_np.max()\n",
    "\n",
    "                softmax = np.exp(feat_np) / np.sum(np.exp(feat_np))\n",
    "\n",
    "                #KH print(max(softmax))\n",
    "        \n",
    "                if max(softmax) > SOFTMAX_THRES:\n",
    "                    idx_ = np.argmax(feat.detach().numpy(), axis=1)[0]\n",
    "        \n",
    "                else:\n",
    "                    idx_ = idx\n",
    "    \n",
    "            else:\n",
    "                #KH print(feat.detach().numpy())\n",
    "                #idx_ = np.argmax(feat.detach().numpy(), axis=1)[0] For demo mobilenet\n",
    "                idx_ = np.argmax(feat.detach().numpy()) # For archnet mobilenet\n",
    "\n",
    "\n",
    "            if HISTORY_LOGIT:\n",
    "                history_logit.append(feat.detach().numpy())\n",
    "                history_logit = history_logit[-int(12/27*num_classes):]\n",
    "                avg_logit = sum(history_logit)\n",
    "                #idx_ = np.argmax(avg_logit, axis=1)[0] For demo mobilenet\n",
    "                idx_ = np.argmax(avg_logit)  #For archnet mobilenet\n",
    "\n",
    "            idx, history = process_output(idx_, history, num_classes)\n",
    "            \n",
    "\n",
    "            t2 = time.time()\n",
    "            print(f\"Final {index} Attempt {catigories[idx]}\")\n",
    "\n",
    "            \n",
    "            current_time = t2 - t1\n",
    "\n",
    "        \n",
    "        img = cv2.resize(img, (640, 480))\n",
    "        img = img[:, ::-1]\n",
    "        height, width, _ = img.shape\n",
    "        label = np.zeros([height // 10, width, 3]).astype('uint8') + 255\n",
    "\n",
    "        #KH cv2.putText(label, 'Prediction: ' + catigories[idx], (0, int(height / 16)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        #KH cv2.putText(label, '{:.1f} Vid/s'.format(1 / current_time), (width - 170, int(height / 16)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "        #KH img = np.concatenate((img, label), axis=0)\n",
    "        #KH cv2.imshow(WINDOW_NAME, img)\n",
    "\n",
    "        #KH key = cv2.waitKey(1)\n",
    "\n",
    "        #KH if key & 0xFF == ord('q') or key == 27:  # exit\n",
    "        #KH     break\n",
    "        \n",
    "        #KH elif key == ord('F') or key == ord('f'):  # full screen\n",
    "        #KH     print('Changing full screen option!')\n",
    "            \n",
    "        #KH     full_screen = not full_screen\n",
    "            \n",
    "        #KH     if full_screen:\n",
    "        #KH         print('Setting FS!!!')\n",
    "        #KH         cv2.setWindowProperty(WINDOW_NAME, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        #KH     \n",
    "        #KH     else:\n",
    "        #KH         cv2.setWindowProperty(WINDOW_NAME, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "\n",
    "\n",
    "        if t is None:\n",
    "            t = time.time()\n",
    "        \n",
    "        else:\n",
    "            nt = time.time()\n",
    "            index += 1\n",
    "            t = nt\n",
    "\n",
    "\n",
    "    #KH cap.release()\n",
    "    #KH cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting... \\n\")\n",
    "\n",
    "    SOFTMAX_THRES = 0\n",
    "    HISTORY_LOGIT = True\n",
    "    REFINE_OUTPUT = True\n",
    "    WINDOW_NAME = \"GESTURE CAPTURE\"\n",
    "\n",
    "    #Modify number of classes here\n",
    "    main(3)\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
